{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraping:\n",
    "    def url_content(self, url):\n",
    "        '''\n",
    "        return de content of web page\n",
    "        \n",
    "        '''\n",
    "        headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0\"}\n",
    "\n",
    "\n",
    "        \n",
    "        # content = requests.get(url, timeout=60)\n",
    "        # soup = BeautifulSoup(content, \"html.parser\")\n",
    "        \n",
    "        response = requests.get(url, timeout=60, headers= headers)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(response.status_code)\n",
    "            result = {\n",
    "                \"lang\": \"None\",\n",
    "                \"url\": \"None\",\n",
    "                \"website_name\": \"None\",\n",
    "                \"content_text\": \"None\"\n",
    "            }\n",
    "            return pd.Series(result)\n",
    "        else:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "            result = {\n",
    "                \"lang\": self.get_language(soup),\n",
    "                \"url\": url,\n",
    "                \"website_name\": self.get_website_name(url),\n",
    "                \"content_text\": self.get_title(soup) + self.get_meta(soup) + self.get_header(soup) + self.get_content(soup)\n",
    "            }\n",
    "        \n",
    "        # return a objet pandas\n",
    "        return pd.Series(result)\n",
    "    \n",
    "    def get_website_name(self, url):\n",
    "        '''return the name that located of the url'''\n",
    "        \n",
    "        return \"\".join(urlparse(url).netloc.split(\".\")[-2])\n",
    "    \n",
    "    def get_title(self, soup):\n",
    "        \n",
    "        return \" \".join(soup.title.contents)\n",
    "    \n",
    "    def get_language(self, soup):\n",
    "        return soup.html.attrs['lang']\n",
    "    \n",
    "    def get_meta(self, soup):\n",
    "        \n",
    "        tags = soup.find_all(lambda tag: (tag.name=='meta') & (tag.has_attr('name') & tag.has_attr('content')))\n",
    "        \n",
    "        content = [str(tag['content']) for tag in tags if tag['name'] in ['keywords', 'description']]\n",
    "        return \" \".join(content)\n",
    "    \n",
    "    def get_header(self, soup):\n",
    "        \n",
    "        tags = soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])\n",
    "        content = [\" \".join(tag.stripped_strings) for tag in tags]\n",
    "        return \" \".join(content)\n",
    "    \n",
    "    def get_content(self, soup):\n",
    "        tags_to_ignore = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\",\"h6\", \"noscript\", \"style\", \"script\", \"head\", \"title\", \"meta\", \"[document]\"]\n",
    "        tags = soup.find_all(text=True)\n",
    "        result = []\n",
    "        for tag in tags:\n",
    "            stripped_tag = tag.strip()\n",
    "            if (\n",
    "                tag.parent.name not in tags_to_ignore\n",
    "                and not isinstance(tag, bs4.element.Comment)\n",
    "                and not stripped_tag.isnumeric()\n",
    "                and len(stripped_tag) > 0\n",
    "            ):\n",
    "                result.append(stripped_tag)\n",
    "                return \" \".join(result)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "sp.prefer_gpu()\n",
    "nlp_en = sp.load(\"en_core_web_sm\")\n",
    "nlp_fr = sp.load(\"fr_core_news_sm\")\n",
    "nlp_de = sp.load(\"de_core_news_sm\")\n",
    "\n",
    "def clean_text(document, lang):\n",
    "    lang_franz = [\"fr\", \"fr-be\", \"fr-ca\", \"fr-ch\", \"fr-lu\", \"fr-FR\"]\n",
    "    lang_deutsch = [\"de\", \"de-ch\", \"de-at\", \"de-lu\", \"de-li\"]\n",
    "               \n",
    "\n",
    "    if lang in lang_franz:\n",
    "        doc = nlp_fr(document)\n",
    "        print(\"****************** Francais ****************************\")\n",
    "    elif lang in lang_deutsch:\n",
    "        doc = nlp_de(document)\n",
    "        print(\"****************** Deutsch ****************************\")\n",
    "    else:\n",
    "        doc = nlp_en(document)\n",
    "        print(\"****************** Autres ****************************\")\n",
    "    \n",
    "    \n",
    "    tokens = []\n",
    "    exclusion_list = [\"nan\"]\n",
    "    \n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct or token.text.isnumeric() or (token.text.isalnum()==False) or token.text in exclusion_list:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        token = str(token.lemma_.lower().strip())\n",
    "        tokens.append(token)\n",
    "    return \" \".join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************** Autres ****************************\n",
      "step inside mukesh ambani sea face ultra luxurious dubai villa worth rs crorein business tycoon mukesh ambani buy luxurious property palm jumeirah dubai worth r crore mukesh ambani mukesh ambani news ambani news nita ambani isha ambani isha ambani news ambani home photo mukesh ambani home photo antilia home photo ambani dubai home photosstep inside mukesh ambani sea face ultra luxurious dubai villa worth rs crore accord report reliance industries limited chairman managing director mukesh ambani buy beachside villa dubai usd million dubai villa mukesh ambani locate northern palm jumeirah luxurious property bedroom private spa swimming pool accord villa furnish italian marble royal masterpiece luxurious property spread area sq ft plot report mukesh ambani villa exterior swimming pool huge pool inside property trend news topics popular stories aditi rao hydari recreate viral tum tum dance rumour boyfriend siddharth watch crow man india man fill sky crow make unique sound fascinating video go viral rohit sharma contrary view virat kohli plan test cricket play manish sisodia arrest early speak potential successor cabinet delhi government source aaliyah kashyap react troll appeal raise fund imtiaz ali daughter ida film view meet aston villa glamorous f streaming week varisu v shahid kapoor birthday chec indulge luxury discover inside pic akshay kumar tw speed read rajasthan internet service suspend hour bharatpur wordle answer today wordle answer march manish sisodia resignation raaj anand get additional charge education health kailash gahlot finance pwd mukesh ambani family member high level security cover sc meet simran bharadwaj top cds exam air give seat crack upsc attempt watch dna original dna exclusive india twitter user year twitter journey elon musk adventure dna exclusive ashok gehlot lead congress gandhis try hit bird stone dna exclusive gandhis remain reluctant congress finally president outside family dna exclusive jungle raj legacy corruption million job nitish pm easy say dna exclusive nitish kumar late flip flop hurt bjp poll\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.dnaindia.com/lifestyle/photo-gallery-inside-photos-of-mukesh-ambani-nita-ambani-luxurious-dubai-villa-worth-rs-650-crore-swimming-pool-interiors-3027060\"\n",
    "\n",
    "scrap = Scraping()\n",
    "content = dict(scrap.url_content(url))\n",
    "\n",
    "#print(content)\n",
    "print()\n",
    "\n",
    "if content[\"lang\"] != \"None\":\n",
    "    text = clean_text(content['content_text'], content['lang'])\n",
    "    print(text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
